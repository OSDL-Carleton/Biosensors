# -*- coding: utf-8 -*-
"""smooth-main-oegfet (V6).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RWf5weF65ryIARkR_B12iweBm_q4Ftag
"""

!pip install pandas
!pip install matplotlib
!pip install scipy
!pip install black[jupyter] --quiet

"https://drive.google.com/drive/folders/1qdPysatcKd2P2pZ9KTqqd9lPTptuKtRM?usp=sharing"

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import os
import matplotlib.pyplot as plt
import numpy as np
import re

folder_path = '/content/drive/My Drive/Masters/Data - FebruaryCSV'

chip_files = {
    'Trial1': [
        'Trial 1_VSD_ISID_20250204_144328.csv',
    ]
}


# ---------------- Part 1: Isd vs Vd Comparison ----------------
def clean_vgs(vgs_value):
    try:

        numeric_part = re.search(r"[-+]?[0-9]*\.?[0-9]+", str(vgs_value))
        if numeric_part:
            return float(numeric_part.group(0))
        else:
            return None
    except Exception as e:
        print(f"Error cleaning Vgs value '{vgs_value}': {e}")
        return None

def extract_values(file_path):
    try:
        df = pd.read_csv(file_path, header=None)
        vgs_values = df.iloc[4, 1:].tolist()
        vgs_values = [clean_vgs(vgs) for vgs in vgs_values]
        mid_point = len(vgs_values) // 2
        vgs_values = vgs_values[:mid_point]

        df = pd.read_csv(file_path, skiprows=4)
        vd_values = df.iloc[:, 0].tolist()
        is_values = df.iloc[:, 1:mid_point + 1]
        id_values = df.iloc[:, mid_point + 1:2 * mid_point + 1]
        isd_values = id_values.subtract(is_values.values)

        for idx, vgs in enumerate(vgs_values):
            is_vals = is_values.iloc[:, idx].tolist()
            id_vals = id_values.iloc[:, idx].tolist()
            isd_vals = isd_values.iloc[:, idx].tolist()
            print(f'For Vgs = {vgs} from {file_path}:')
            print(f'  Is values: {is_vals}')
            print(f'  Id values: {id_vals}')
            print(f'  Isd values: {isd_vals}')

        return vd_values, vgs_values, is_values, id_values, isd_values
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
        return None, None, None, None, None

def compute_average_isd(tool, files):
    combined_isd = None
    vgs_values = None
    vd_values = None

    for file_name in files:
        file_path = os.path.join(folder_path, tool, file_name)
        if os.path.exists(file_path):
            vd_vals, vgs_vals, _, _, isd_values = extract_values(file_path)
            if isd_values is not None:
                if combined_isd is None:
                    combined_isd = isd_values
                    vgs_values = vgs_vals
                    vd_values = vd_vals
                else:
                    combined_isd = combined_isd.add(isd_values, fill_value=0)
        else:
            print(f"File not found: {file_path}")

    if combined_isd is not None and len(files) > 0:
        average_isd = combined_isd / len(files)
        return vd_values, vgs_values, average_isd
    else:
        return None, None, None

average_isd_values = {}

for tool, files in chip_files.items():
    vd_values, vgs_values, average_isd = compute_average_isd(tool, files)
    if vgs_values is not None and average_isd is not None:
        average_isd_values[tool] = (vd_values, vgs_values, average_isd)

for tool, (vd_values, vgs_values, avg_isd) in average_isd_values.items():
    print(f"\nSummary for {tool}:")
    print(f"  Vd values: {vd_values}")
    print(f"  Vgs values: {vgs_values}")
    for idx, vgs in enumerate(vgs_values):
        avg_isd_vals = avg_isd.iloc[:, idx].tolist()
        print(f'  Average Isd values for Vgs = {vgs}: {avg_isd_vals}')

def get_focused_summary(average_isd_values, target_vgs):
    target_vgs_float = clean_vgs(target_vgs)
    focused_data = {}

    print(f"\n--- Focused Summary for Vgs = {target_vgs} ---\n")
    for tool, (vd_values, vgs_values, avg_isd) in average_isd_values.items():
        if target_vgs_float not in vgs_values:
            print(f"Target Vgs = {target_vgs} not found for tool {tool}. Skipping.")
            continue

        idx = vgs_values.index(target_vgs_float)
        avg_isd_vals = avg_isd.iloc[:, idx].tolist()
        print(f"Tool: {tool}")
        print(f"  Vd values: {vd_values}")
        print(f"  Average Isd values for Vgs = {target_vgs}: {avg_isd_vals}")
        focused_data[tool] = (vd_values, avg_isd_vals)

    return focused_data

def plot_focused_summary(focused_data, target_vgs):
    if not focused_data:
        print("No data found for the specified Vgs. Skipping plot.")
        return

    print(f"\n--- Plotting Focused Summary for Vgs = {target_vgs} ---\n")
    plt.figure(figsize=(10, 6))

    for tool, (vd_values, avg_isd_vals) in focused_data.items():
        # plt.plot(vd_values, avg_isd_vals, label=f'Isd for {tool} (Vgs = {target_vgs})')
        # transformed_isd_vals = np.abs(np.sqrt(avg_isd_vals))
        transformed_isd_vals = np.sqrt(np.abs(avg_isd_vals))
        plt.plot(vd_values, transformed_isd_vals, label=f'Transformed Isd for {tool} (Vgs = {target_vgs})')

    plt.title(f'Isd vs Vd Comparison at Vgs = {target_vgs}')
    plt.xlabel('Vd (V)')
    plt.ylabel('Isd (A)')
    plt.legend()
    plt.grid(True)
    plt.show()

def plot_all_vgs(average_isd_values):
    """
    Plots Isd vs Vd for all Vgs values across different datasets.
    """
    if not average_isd_values:
        print("No data available for plotting.")
        return

    print("\n--- Plotting Isd vs Vd for all Vgs values ---\n")

    plt.figure(figsize=(10, 6))

    for tool, (vd_values, vgs_values, avg_isd) in average_isd_values.items():
        for idx, vgs in enumerate(vgs_values):
            isd_vals = avg_isd.iloc[:, idx].tolist()
            transformed_isd_vals = np.sqrt(np.abs(isd_vals))  # Transform for visualization

            plt.plot(vd_values, transformed_isd_vals, label=f'{tool}: Vgs = {vgs}')

    plt.title('Isd vs Vd for All Vgs Values')
    plt.xlabel('Vd (V)')
    plt.ylabel('Isd (A)')
    plt.legend(loc="best", fontsize="small", ncol=2)  # Adjust legend for better visualization
    plt.grid(True)
    plt.show()

def get_all_vgs_data(vd_values, vgs_values, isd_values):
    """
    Stores Isd vs Vd data for all Vgs values in a structured format.
    Returns a dictionary where each Vgs has its corresponding Vd and Isd values.
    """
    all_vgs_data = {}

    for idx, vgs in enumerate(vgs_values):
        isd_vals = isd_values.iloc[:, idx].tolist()
        all_vgs_data[vgs] = (vd_values, isd_vals)  # Store Vd and Isd pairs

    return all_vgs_data



# Call the function to plot all Vgs values
plot_all_vgs(average_isd_values)


target_vgs = '0.5'
focused_data = get_focused_summary(average_isd_values, target_vgs)
plot_focused_summary(focused_data, target_vgs)

from scipy.signal import savgol_filter
import numpy as np
import matplotlib.pyplot as plt


def smooth_data(data, window_length=7, polyorder=2):
    if len(data) < window_length:
        print("Warning: Data length is less than the smoothing window. Returning original data.")
        return np.array(data)

    window_length = min(len(data), window_length)
    if window_length % 2 == 0:
        window_length -= 1

    return savgol_filter(data, window_length, polyorder)

def store_smoothed_data(focused_data, smooth_window=7, polyorder=2):
    smoothed_data = {}

    for tool, (vd_values, avg_isd_vals) in focused_data.items():
        # transformed_isd_vals = np.abs(np.sqrt(avg_isd_vals))
        transformed_isd_vals = np.sqrt(np.abs(avg_isd_vals))
        smoothed_isd_vals = smooth_data(transformed_isd_vals, window_length=smooth_window, polyorder=polyorder)
        smoothed_data[tool] = (vd_values, smoothed_isd_vals)

    return smoothed_data

def plot_smoothed_data(smoothed_data, target_vgs):
    plt.figure(figsize=(10, 6))

    for tool, (vd_values, smoothed_isd_vals) in smoothed_data.items():
        plt.plot(vd_values, smoothed_isd_vals, label=f'{tool} Smoothed Data')

    plt.title(f'Smoothed Isd vs Vsd at Vgs = {target_vgs}')
    plt.xlabel('Vsd (V)')
    plt.ylabel('Smoothed Isd (A)')
    plt.legend()
    plt.grid(True)
    plt.show()


def plot_smoothed_data(smoothed_data, target_vgs):
    plt.figure(figsize=(10, 6))

    for tool, (vd_values, smoothed_isd_vals) in smoothed_data.items():
        plt.plot(vd_values, smoothed_isd_vals, label=f'{tool} Smoothed Data')

    plt.title(f'Smoothed Isd vs Vsd at Vgs = {target_vgs}')
    plt.xlabel('Vsd (V)')
    plt.ylabel('Smoothed Isd (A)')
    plt.legend()
    plt.grid(True)
    plt.show()




smooth_window = 13
polyorder = 3
smoothed_data = store_smoothed_data(focused_data, smooth_window, polyorder)

plot_smoothed_data(smoothed_data, target_vgs)

# Retrieve all Vgs data
all_vgs_data = get_all_vgs_data(average_isd_values)

# Smooth all Vgs data
smoothed_vgs_data = smooth_all_vgs_data(all_vgs_data)

# Call the function to plot smoothed Isd vs Vd for all Vgs values using smoothed Vgs data
plot_smoothed_all_vgs(smoothed_vgs_data)

from scipy.signal import savgol_filter
import numpy as np
import matplotlib.pyplot as plt

def calculate_slope(x, y):
    slope, intercept = np.polyfit(x, y, 1)
    return slope, intercept

def find_intersection(slope1, intercept1, slope2, intercept2):
    if slope1 == slope2:
        print("The lines are parallel and do not intersect.")
        return None, None
    x_intersect = (intercept2 - intercept1) / (slope1 - slope2)
    y_intersect = slope1 * x_intersect + intercept1
    return x_intersect, y_intersect

def smooth_data(data, window_length=7, polyorder=2):
    if len(data) < window_length:
        print("Warning: Data length is less than the smoothing window. Returning original data.")
        return np.array(data)
    window_length = min(len(data), window_length)
    if window_length % 2 == 0:
        window_length -= 1
    return savgol_filter(data, window_length, polyorder)

def analyze_smoothed_data(smoothed_data, regions):
    plt.figure(figsize=(12, 8))

    for (tool, (vd_values, smoothed_isd_vals)), tool_regions in zip(smoothed_data.items(), regions):
        vd_values = np.array(vd_values)
        smoothed_isd_vals = np.array(smoothed_isd_vals)



        slopes = []
        for i, (x_start, x_end) in enumerate(tool_regions):

            valid_indices = np.where((vd_values >= x_start) & (vd_values <= x_end))[0]
            if len(valid_indices) == 0:
                print(f"No valid data points in range ({x_start}, {x_end}) for {tool}. Skipping.")
                continue

            region_x = vd_values[valid_indices]
            region_y = smoothed_isd_vals[valid_indices]

            slope, intercept = calculate_slope(region_x, region_y)
            slopes.append((slope, intercept))

            x_full = np.linspace(vd_values.min(), vd_values.max(), 500)
            y_full = slope * x_full + intercept
            #plt.plot(x_full, y_full, linestyle='--', label=f'{tool} Slope {i+1}: {slope:.2e}')

        if len(slopes) >= 2:
            # Compute intersection
            slope1, intercept1 = slopes[0]
            slope2, intercept2 = slopes[1]
            x_intersect, y_intersect = find_intersection(slope1, intercept1, slope2, intercept2)

            if x_intersect is not None and y_intersect is not None:
                smoothed_isd_vals[vd_values >= x_intersect] = y_intersect  # Constant after intersection
                plt.plot(vd_values, smoothed_isd_vals, label=f'{tool} Smoothed Data', alpha=0.4)
                plt.plot(x_intersect, y_intersect, 'o', label=f'{tool} Intersection ({x_intersect:.2f}, {y_intersect:.2e})')



    plt.title('Slope and Intersection Analysis')
    plt.xlabel('Vd (V)')
    plt.ylabel('Smoothed Isd (A)')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
    plt.grid(True)
    plt.show()


regions = [
    [(1.5, 1.7), (1.8, 2)],
    [(1.5, 1.7), (1.8, 2)],
    [(1.5, 1.7), (1.8, 2)],
    [(1.5, 1.7), (1.8, 2)],
    [(1.5, 1.7), (1.8, 2)],
    [(1.5, 1.7), (1.8, 2)],
    [(1.5, 1.7), (1.8, 2)],
]

analyze_smoothed_data(smoothed_data, regions)



from scipy.signal import savgol_filter
import numpy as np
import matplotlib.pyplot as plt

def calculate_slope(x, y):
    if len(x) < 2:
        return None, None
    slope, intercept = np.polyfit(x, y, 1)
    return slope, intercept

def find_intersection(slope1, intercept1, slope2, intercept2):
    if slope1 == slope2:
        return None, None  # Parallel lines
    x_intersect = (intercept2 - intercept1) / (slope1 - slope2)
    y_intersect = slope1 * x_intersect + intercept1
    return x_intersect, y_intersect

def smooth_data(data, window_length=7, polyorder=2):
    if len(data) < window_length:
        return np.array(data)
    window_length = min(len(data), window_length)
    if window_length % 2 == 0:
        window_length -= 1
    return savgol_filter(data, window_length, polyorder)

def identify_segments(vd_values, smoothed_isd_vals):
    slopes = []
    segment_length = max(3, len(vd_values) // 20)  # Ensure meaningful segments

    for i in range(len(vd_values) - segment_length):
        x_segment = vd_values[i:i + segment_length]
        y_segment = smoothed_isd_vals[i:i + segment_length]
        slope, intercept = calculate_slope(x_segment, y_segment)
        if slope is not None:
            slopes.append((vd_values[i], slope, intercept))

    slopes = np.array(slopes)
    x_vals, slope_vals, intercept_vals = slopes[:, 0], slopes[:, 1], slopes[:, 2]

    # Automatically determine thresholds
    slope_median = np.median(np.abs(slope_vals))
    horizontal_threshold = 0.1 * slope_median  # Small fraction for horizontal
    vertical_threshold = 10 * slope_median    # Larger multiple for vertical

    # Identify near-horizontal and near-vertical segments
    horizontal_indices = np.where(np.abs(slope_vals) < horizontal_threshold)[0]
    vertical_indices = np.where(np.abs(slope_vals) > vertical_threshold)[0]

    if len(horizontal_indices) == 0 or len(vertical_indices) == 0:
        print("Could not identify horizontal or vertical regions.")
        return None, None

    # Select the last horizontal and vertical segments
    last_horizontal_idx = horizontal_indices[-1]
    last_vertical_idx = vertical_indices[-1]

    slope_h, intercept_h = slope_vals[last_horizontal_idx], intercept_vals[last_horizontal_idx]
    slope_v, intercept_v = slope_vals[last_vertical_idx], intercept_vals[last_vertical_idx]

    return (slope_h, intercept_h), (slope_v, intercept_v)


def analyze_smoothed_data(smoothed_data):
    plt.figure(figsize=(12, 8))

    for tool, (vd_values, smoothed_isd_vals) in smoothed_data.items():
        vd_values = np.array(vd_values)
        smoothed_isd_vals = np.array(smoothed_isd_vals)

        # Identify the last near-horizontal and near-vertical segments dynamically
        horizontal_segment, vertical_segment = identify_segments(vd_values, smoothed_isd_vals)

        if horizontal_segment and vertical_segment:
            slope_h, intercept_h = horizontal_segment
            slope_v, intercept_v = vertical_segment

            # Compute the intersection
            x_intersect, y_intersect = find_intersection(slope_h, intercept_h, slope_v, intercept_v)

            # Apply correction by setting constant values after the intersection
            if x_intersect is not None and y_intersect is not None:
                smoothed_isd_vals[vd_values >= x_intersect] = y_intersect

                plt.plot(vd_values, smoothed_isd_vals, label=f'{tool} Smoothed Data', alpha=0.6)
                plt.plot(x_intersect, y_intersect, 'ro', label=f'{tool} Intersection ({x_intersect:.2f}, {y_intersect:.2e})')

    plt.title('Slope and Intersection Analysis (Dynamic)')
    plt.xlabel('Vd (V)')
    plt.ylabel('Smoothed Isd (A)')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
    plt.grid(True)
    plt.show()

analyze_smoothed_data(smoothed_data)

def format_filtered_average_isd_with_vd_range(average_isd_values, vd_steps):
    vgs_list = average_isd_values[list(average_isd_values.keys())[0]][1]
    formatted_dict = {vd: [None] for vd in vd_steps}

    for vgs_idx, vgs in enumerate(vgs_list):
        for vd in vd_steps:
            combined_isd = []

            for tool, (vd_values, _, avg_isd) in average_isd_values.items():
                filtered_isd_vals = [
                    avg_isd.iloc[i, vgs_idx]
                    for i, vd_value in enumerate(vd_values)
                    if abs(vd_value - vd) < 0.05
                ]
                combined_isd.extend(filtered_isd_vals)

            avg_isd_for_vgs = np.mean(combined_isd) if combined_isd else None
            if avg_isd_for_vgs is not None:
                formatted_dict[vd][0] = avg_isd_for_vgs

    return formatted_dict, vgs_list

def plot_isd_vs_vsg(vsg_values, filtered_avg_isd_values):
    plt.figure(figsize=(10, 6))
    for vd, isd_values in filtered_avg_isd_values.items():
        plt.plot(vsg_values, isd_values, label=f'Vd = {vd:.1f}')

    plt.xlabel('Vsg (V)')
    plt.ylabel('Isd (A)')
    plt.legend(title='Vd values', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.title('Isd vs Vsg for Discrete Vd Values')
    plt.grid(True)
    plt.tight_layout()
    plt.show()

vd_steps = [round(vd, 1) for vd in np.arange(0.1, 1.1, 0.1)]
filtered_avg_isd_values, vsg_values = format_filtered_average_isd_with_vd_range(average_isd_values, vd_steps)

print("y_values = {")
for vd, isd_values in filtered_avg_isd_values.items():
    print(f"  {vd}: {isd_values},")
print("}")

plot_isd_vs_vsg(vsg_values, filtered_avg_isd_values)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from scipy.interpolate import make_interp_spline

x_values = np.array([0, 0.400000, 0.800000, 1.200000, 1.600000, 2.000000, 2.400000, 2.800000])

y_values = {
  0.0: [-1.821809523809524e-09, 3.9600952380952374e-09, 5.010000000000001e-09, 5.738809523809523e-09, 6.2465238095238085e-09, 6.484238095238096e-09, 6.839809523809523e-09, 7.1043809523809535e-09],
  0.1: [-2.1223809523809523e-09, 1.3275714285714284e-09, 1.8404285714285714e-09, 2.528571428571429e-09, 2.9019047619047626e-09, 3.1759999999999994e-09, 3.3373333333333334e-09, 3.4851428571428575e-09],
  0.2: [-2.2217142857142855e-09, -1.3942857142857139e-10, -1.2057142857142862e-10, 8.076190476190472e-11, 4.17e-10, 4.1404761904761907e-10, 4.816666666666667e-10, 5.537142857142859e-10],
  0.3: [-2.3825714285714284e-09, -1.1242857142857143e-09, -1.2926190476190476e-09, -1.0373333333333333e-09, -9.536190476190476e-10, -9.045714285714285e-10, -7.918095238095239e-10, -8.404761904761905e-10],
  0.4: [-2.7148571428571434e-09, -2.194714285714286e-09, -2.3321904761904764e-09, -2.209142857142857e-09, -2.2386190476190474e-09, -2.0320952380952383e-09, -2.055095238095238e-09, -2.1862380952380952e-09],
  0.5: [-3.083761904761904e-09, -2.965190476190476e-09, -3.5573333333333335e-09, -3.2489047619047615e-09, -3.2251428571428576e-09, -3.092857142857143e-09, -3.169904761904762e-09, -3.3055714285714286e-09],
  0.6: [-3.591952380952381e-09, -4.020809523809524e-09, -4.692142857142858e-09, -4.491095238095237e-09, -4.535380952380952e-09, -4.336e-09, -4.385666666666667e-09, -4.270714285714285e-09],
  0.7: [-4.133380952380952e-09, -5.186095238095237e-09, -5.883428571428572e-09, -5.746476190476191e-09, -5.86e-09, -5.816952380952381e-09, -5.950000000000001e-09, -5.7455238095238095e-09],
  0.8: [-4.818e-09, -6.033619047619048e-09, -6.974e-09, -7.184904761904762e-09, -7.043904761904762e-09, -7.264142857142857e-09, -7.2998095238095234e-09, -7.1228571428571435e-09],
  0.9: [-5.426904761904762e-09, -6.825619047619048e-09, -7.880809523809524e-09, -8.27304761904762e-09, -8.41957142857143e-09, -8.383380952380953e-09, -8.74757142857143e-09, -8.533333333333332e-09],
  1.0: [-6.132666666666666e-09, -7.621285714285715e-09, -8.772190476190475e-09, -9.319095238095237e-09, -9.575238095238094e-09, -9.760904761904763e-09, -9.988428571428572e-09, -1.0093666666666668e-08],
}


threshold_vgs = 2.0

plt.figure(figsize=(10, 6))
gm_values = {}
curve_labels = {}

all_max_slopes = []
for key, values in y_values.items():
    spline = make_interp_spline(x_values, values, k=3)
    x_smooth = np.linspace(x_values.min(), x_values.max(), 300)
    y_smooth = spline(x_smooth)

    slopes = np.diff(y_smooth) / np.diff(x_smooth)
    all_max_slopes.append(np.max(np.abs(slopes)))

threshold_for_off = np.percentile(all_max_slopes, 50)

for key, values in y_values.items():
    spline = make_interp_spline(x_values, values, k=3)
    x_smooth = np.linspace(x_values.min(), x_values.max(), 300)
    y_smooth = spline(x_smooth)

    slopes = np.diff(y_smooth) / np.diff(x_smooth)
    max_slope = np.max(np.abs(slopes))

    if max_slope < threshold_for_off:
        curve_labels[key] = "Off"
        plt.plot(x_smooth, y_smooth, label=f'{key} (Off)', linestyle='-.')
    else:
        curve_labels[key] = "On"
        slopes_right_to_left = np.diff(y_smooth[::-1]) / np.diff(x_smooth[::-1])
        on_region_start_index = len(slopes_right_to_left) - np.argmax(slopes_right_to_left > np.percentile(slopes_right_to_left, 75)) - 1

        if on_region_start_index < len(x_smooth):
            x_on_region = x_smooth[on_region_start_index:].reshape(-1, 1)
            y_on_region = y_smooth[on_region_start_index:].reshape(-1, 1)

            reg = LinearRegression().fit(x_on_region, y_on_region)
            gm = reg.coef_[0][0]
            gm_values[key] = gm

            plt.plot(x_smooth, y_smooth, label=f'{key} (On)')
            plt.plot(x_on_region, reg.predict(x_on_region), linestyle='--')

            extension_factor = 0.1
            extended_x = np.linspace(x_smooth[on_region_start_index] - extension_factor, x_smooth[-1] + extension_factor, 100).reshape(-1, 1)
            # extended_x = np.linspace(x_smooth[on_region_start_index], x_smooth[-1], 100).reshape(-1, 1)
            plt.plot(extended_x, reg.predict(extended_x), linestyle=':', linewidth=2, label=f'Slope {key} (gm={gm:.4f}, R^2={reg.score(x_on_region, y_on_region):.2f})')
        else:
            gm_values[key] = np.nan

plt.xlabel('VGS (V)')
plt.ylabel('Isd (A)')
plt.legend(title='Vd values', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.title('Isd vs VGS with gm slopes (On/Off Region)')
plt.grid(True)
plt.show()

for key, gm in gm_values.items():
    label = curve_labels[key]
    if label == "On":
        print(f'gm for Vd = {key} (On): {gm:.4f}')
    else:
        print(f'Curve for Vd = {key} is Off, showing linear or inactive behavior.')