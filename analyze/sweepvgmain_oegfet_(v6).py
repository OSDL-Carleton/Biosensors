# -*- coding: utf-8 -*-
"""sweepVgmain-oegfet (V6).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12tu3__0WeNjiUemp8nQi8FK1QLfXU1CL
"""

!pip install pandas
!pip install matplotlib
!pip install scipy
!pip install black[jupyter] --quiet

"https://drive.google.com/drive/folders/1qdPysatcKd2P2pZ9KTqqd9lPTptuKtRM?usp=sharing"

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import os
import matplotlib.pyplot as plt
import numpy as np
import re

folder_path = '/content/drive/My Drive/Masters/Data - Bionsensor V2 (February 28, 2025)'

chip_files = {
    'Sample 4 - 20250228_145125': [
        'Sample 4_VSD_ISID_20250228_145125.csv',
    ],
    # 'Sample 5 - 20250228_143835': [
    #     'Sample 5_VSD_ISID_20250228_143835.csv',
    # ],
    # 'Sample 6 - 20250228_142242': [
    #     'Sample 6_VSD_ISID_20250228_142242.csv',
    # ],
}

def clean_vd(vd_value):
    try:
        numeric_part = re.search(r"[-+]?[0-9]*\.?[0-9]+", str(vd_value))
        if numeric_part:
            return float(numeric_part.group(0))
        else:
            return None
    except Exception as e:
        print(f"Error cleaning Vd value '{vd_value}': {e}")
        return None

def extract_values(file_path):
    try:
        df = pd.read_csv(file_path, header=None)
        vd_values = df.iloc[4, 1:].dropna().tolist()
        vd_values = [clean_vd(vd) for vd in vd_values if pd.notna(vd)]
        mid_point = len(vd_values) // 2
        vd_values = vd_values[:mid_point]

        df = pd.read_csv(file_path, skiprows=4).dropna()
        vg_values = df.iloc[:, 0].tolist()
        is_values = df.iloc[:, 1:mid_point + 1].dropna()
        id_values = df.iloc[:, mid_point + 1:2 * mid_point + 1].dropna()
        isd_values = id_values.subtract(is_values.values, fill_value=0).dropna()

        return vg_values, vd_values, is_values, id_values, isd_values
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
        return None, None, None, None, None

def compute_average_isd(tool, files):
    combined_isd = None
    vd_values = None
    vg_values = None

    for file_name in files:
        file_path = os.path.join(folder_path, tool, file_name)
        if os.path.exists(file_path):
            vg_vals, vd_vals, is_values, _, isd_values = extract_values(file_path)
            if isd_values is not None:
                if combined_isd is None:
                    combined_isd = isd_values
                    vd_values = vd_vals
                    vg_values = vg_vals
                else:
                    combined_isd = combined_isd.add(isd_values, fill_value=0)
        else:
            print(f"File not found: {file_path}")

    if combined_isd is not None and len(files) > 0:
        average_isd = combined_isd / len(files)
        return vg_values, vd_values, average_isd, is_values
    else:
        return None, None, None, None

average_isd_values = {}

for tool, files in chip_files.items():
    vg_values, vd_values, average_isd, is_values = compute_average_isd(tool, files)
    if vd_values is not None and average_isd is not None:
        average_isd_values[tool] = (vg_values, vd_values, average_isd, is_values)

def get_focused_summary(average_isd_values, target_vds):
    focused_data = {}

    for target_vd in target_vds:
        target_vd_float = clean_vd(target_vd)
        for tool, (vg_values, vd_values, avg_isd, is_values) in average_isd_values.items():
            if target_vd_float not in vd_values:
                continue

            idx = vd_values.index(target_vd_float)
            avg_isd_vals = avg_isd.iloc[:, idx].dropna().tolist()
            is_values_list = is_values.iloc[:, idx].dropna().tolist()

            if tool not in focused_data:
                focused_data[tool] = {}

            focused_data[tool][target_vd] = (vg_values, is_values_list)

    return focused_data

def plot_focused_summary(focused_data):
    if not focused_data:
        print("No data found for the specified Vd. Skipping plot.")
        return

    plt.figure(figsize=(10, 6))

    for tool, vd_data in focused_data.items():
        for target_vd, (vg_values, is_values) in vd_data.items():
            plt.plot(vg_values, is_values, label=f'Transformed Isd for {tool} (Vd = {target_vd})')

    plt.title('Isd vs Vg Comparison at Multiple Vd Values')
    plt.xlabel('Vg (V)')
    plt.ylabel('Isd (A)')
    plt.legend()
    plt.grid(True)
    plt.show()

target_vds = [0.25, 0.5, 0.75, 1]
focused_data = get_focused_summary(average_isd_values, target_vds)
plot_focused_summary(focused_data)

from scipy.signal import savgol_filter
import numpy as np
import matplotlib.pyplot as plt

def smooth_data(data, window_length=7, polyorder=2):
    if len(data) < window_length:
        print("Warning: Data length is less than the smoothing window. Returning original data.")
        return np.array(data)

    window_length = min(len(data), window_length)
    if window_length % 2 == 0:
        window_length -= 1

    return savgol_filter(data, window_length, polyorder)

def store_smoothed_data(focused_data, smooth_window=7, polyorder=2):
    smoothed_data = {}

    for tool, vd_dict in focused_data.items():
        smoothed_data[tool] = {}
        for target_vd, (vg_values, is_values) in vd_dict.items():
            smoothed_is_vals = smooth_data(is_values, window_length=smooth_window, polyorder=polyorder)
            smoothed_data[tool][target_vd] = (vg_values, smoothed_is_vals)

    return smoothed_data

def plot_smoothed_data(smoothed_data):
    plt.figure(figsize=(10, 6))

    for tool, vd_dict in smoothed_data.items():
        for target_vd, (vg_values, smoothed_isd_vals) in vd_dict.items():
            plt.plot(vg_values, smoothed_isd_vals, label=f'{tool} Smoothed Data (Vd = {target_vd})')

    plt.title('Isd vs Vg at Multiple Vd Values')
    plt.xlabel('Vg (V)')
    plt.ylabel('Isd (A)')
    plt.legend()
    plt.grid(True)
    plt.show()

smoothed_data = store_smoothed_data(focused_data, smooth_window=13, polyorder=3)
plot_smoothed_data(smoothed_data)

from scipy.signal import savgol_filter
import numpy as np
import matplotlib.pyplot as plt

def calculate_slope(x, y):
    if len(x) < 2 or len(y) < 2:
        print("Not enough data points to calculate slope.")
        return None, None
    if np.all(y == y[0]):
        print("Warning: Y values are constant, slope will be zero.")
        return 0, y[0]
    slope, intercept = np.polyfit(x, y, 1)
    return slope, intercept

def find_intersection(slope1, intercept1, slope2, intercept2):
    if slope1 == slope2:
        print("The lines are parallel and do not intersect.")
        return None, None
    x_intersect = (intercept2 - intercept1) / (slope1 - slope2)
    y_intersect = slope1 * x_intersect + intercept1
    return x_intersect, y_intersect

def smooth_data(data, window_length=7, polyorder=2):
    if len(data) < window_length:
        print("Warning: Data length is less than the smoothing window. Returning original data.")
        return np.array(data)
    window_length = min(len(data), window_length)
    if window_length % 2 == 0:
        window_length -= 1
    return savgol_filter(data, window_length, polyorder)

def calculate_slope(x, y):
    if len(x) < 2 or len(y) < 2:
        return None, None
    slope, intercept = np.polyfit(x, y, 1)
    return slope, intercept

def analyze_smoothed_data(smoothed_data):
    plt.figure(figsize=(12, 8))
    slopes = {}

    for tool, vd_dict in smoothed_data.items():
        slopes[tool] = {}
        for target_vd, (vg_values, smoothed_isd_vals) in vd_dict.items():
            vg_values = np.array(vg_values)
            smoothed_isd_vals = np.array(smoothed_isd_vals)

            valid_indices = np.where((vg_values >= 1.5) & (vg_values <= 3))[0]
            if len(valid_indices) == 0:
                continue

            region_x = vg_values[valid_indices]
            region_y = smoothed_isd_vals[valid_indices]

            overall_slope, overall_intercept = calculate_slope(region_x, region_y)
            if overall_slope is not None:
                slopes[tool][target_vd] = overall_slope
                y_fit = overall_slope * region_x + overall_intercept
                plt.plot(region_x, y_fit, linestyle='--', label=f'{tool} Fit Line (Vd={target_vd})')

            plt.plot(vg_values, smoothed_isd_vals, label=f'{tool} Smoothed Data (Vd={target_vd})', alpha=0.4)

    plt.title('Slope Analysis for Smoothed Data')
    plt.xlabel('Vg (V)')
    plt.ylabel('Smoothed Isd (A)')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
    plt.grid(True)
    plt.show()

    return slopes

transconductance = analyze_smoothed_data(smoothed_data)
print("Calculated Transconductance:", transconductance)

def compute_k_and_Id_sat(smoothed_data):
    k_values = {}
    Id_sat_values = {}

    for tool, vd_dict in smoothed_data.items():
        k_values[tool] = {}
        Id_sat_values[tool] = {}

        for target_vd, (vg_values, smoothed_id_values) in vd_dict.items():
            vg_values_arr = np.array(vg_values)
            smoothed_id_values_arr = np.array(smoothed_id_values)

            # Estimate Vt by finding the first point where Id > 0
            Vt_index = np.where(smoothed_id_values_arr > 0)[0][0]
            Vt = vg_values_arr[Vt_index]

            # Choose a point in the saturation region (highest Vgs)
            Vgs_at_Id_sat = vg_values_arr[-1]
            Id_at_Id_sat = smoothed_id_values_arr[-1]

            # Compute k
            if (Vgs_at_Id_sat - Vt) > 0:
                k = Id_at_Id_sat / (Vgs_at_Id_sat - Vt) ** 2
            else:
                k = 0  # Avoid division by zero

            k_values[tool][target_vd] = k

            # Compute Id_sat using k
            Id_sat = k * (Vgs_at_Id_sat - Vt) ** 2
            Id_sat_values[tool][target_vd] = Id_sat

            print(f"Tool: {tool}, Vd: {target_vd}")
            print(f"Vt: {Vt:.2f}, Vgs_at_Id_sat: {Vgs_at_Id_sat:.2f}, Id_at_Id_sat: {Id_at_Id_sat:.2e}")
            print(f"k: {k:.2e}, Id_sat: {Id_sat:.2e}\n")

    return k_values, Id_sat_values

# Run the computation
k_values, Id_sat_values = compute_k_and_Id_sat(smoothed_data)

def format_filtered_average_isd_with_vd_range(average_isd_values, vd_steps):
    vgs_list = average_isd_values[list(average_isd_values.keys())[0]][1]
    formatted_dict = {vd: [None] for vd in vd_steps}

    for vgs_idx, vgs in enumerate(vgs_list):
        for vd in vd_steps:
            combined_isd = []

            for tool, (vd_values, _, avg_isd) in average_isd_values.items():
                filtered_isd_vals = [
                    avg_isd.iloc[i, vgs_idx]
                    for i, vd_value in enumerate(vd_values)
                    if abs(vd_value - vd) < 0.05
                ]
                combined_isd.extend(filtered_isd_vals)

            avg_isd_for_vgs = np.mean(combined_isd) if combined_isd else None
            if avg_isd_for_vgs is not None:
                formatted_dict[vd][0] = avg_isd_for_vgs

    return formatted_dict, vgs_list

def plot_isd_vs_vsg(vsg_values, filtered_avg_isd_values):
    plt.figure(figsize=(10, 6))
    for vd, isd_values in filtered_avg_isd_values.items():
        plt.plot(vsg_values, isd_values, label=f'Vd = {vd:.1f}')

    plt.xlabel('Vsg (V)')
    plt.ylabel('Isd (A)')
    plt.legend(title='Vd values', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.title('Isd vs Vsg for Discrete Vd Values')
    plt.grid(True)
    plt.tight_layout()
    plt.show()

vd_steps = [round(vd, 1) for vd in np.arange(0.1, 1.1, 0.1)]
filtered_avg_isd_values, vsg_values = format_filtered_average_isd_with_vd_range(average_isd_values, vd_steps)

print("y_values = {")
for vd, isd_values in filtered_avg_isd_values.items():
    print(f"  {vd}: {isd_values},")
print("}")

plot_isd_vs_vsg(vsg_values, filtered_avg_isd_values)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from scipy.interpolate import make_interp_spline

x_values = np.array([0, 0.400000, 0.800000, 1.200000, 1.600000, 2.000000, 2.400000, 2.800000])

y_values = {
  0.0: [-1.821809523809524e-09, 3.9600952380952374e-09, 5.010000000000001e-09, 5.738809523809523e-09, 6.2465238095238085e-09, 6.484238095238096e-09, 6.839809523809523e-09, 7.1043809523809535e-09],
  0.1: [-2.1223809523809523e-09, 1.3275714285714284e-09, 1.8404285714285714e-09, 2.528571428571429e-09, 2.9019047619047626e-09, 3.1759999999999994e-09, 3.3373333333333334e-09, 3.4851428571428575e-09],
  0.2: [-2.2217142857142855e-09, -1.3942857142857139e-10, -1.2057142857142862e-10, 8.076190476190472e-11, 4.17e-10, 4.1404761904761907e-10, 4.816666666666667e-10, 5.537142857142859e-10],
  0.3: [-2.3825714285714284e-09, -1.1242857142857143e-09, -1.2926190476190476e-09, -1.0373333333333333e-09, -9.536190476190476e-10, -9.045714285714285e-10, -7.918095238095239e-10, -8.404761904761905e-10],
  0.4: [-2.7148571428571434e-09, -2.194714285714286e-09, -2.3321904761904764e-09, -2.209142857142857e-09, -2.2386190476190474e-09, -2.0320952380952383e-09, -2.055095238095238e-09, -2.1862380952380952e-09],
  0.5: [-3.083761904761904e-09, -2.965190476190476e-09, -3.5573333333333335e-09, -3.2489047619047615e-09, -3.2251428571428576e-09, -3.092857142857143e-09, -3.169904761904762e-09, -3.3055714285714286e-09],
  0.6: [-3.591952380952381e-09, -4.020809523809524e-09, -4.692142857142858e-09, -4.491095238095237e-09, -4.535380952380952e-09, -4.336e-09, -4.385666666666667e-09, -4.270714285714285e-09],
  0.7: [-4.133380952380952e-09, -5.186095238095237e-09, -5.883428571428572e-09, -5.746476190476191e-09, -5.86e-09, -5.816952380952381e-09, -5.950000000000001e-09, -5.7455238095238095e-09],
  0.8: [-4.818e-09, -6.033619047619048e-09, -6.974e-09, -7.184904761904762e-09, -7.043904761904762e-09, -7.264142857142857e-09, -7.2998095238095234e-09, -7.1228571428571435e-09],
  0.9: [-5.426904761904762e-09, -6.825619047619048e-09, -7.880809523809524e-09, -8.27304761904762e-09, -8.41957142857143e-09, -8.383380952380953e-09, -8.74757142857143e-09, -8.533333333333332e-09],
  1.0: [-6.132666666666666e-09, -7.621285714285715e-09, -8.772190476190475e-09, -9.319095238095237e-09, -9.575238095238094e-09, -9.760904761904763e-09, -9.988428571428572e-09, -1.0093666666666668e-08],
}


threshold_vgs = 2.0

plt.figure(figsize=(10, 6))
gm_values = {}
curve_labels = {}

all_max_slopes = []
for key, values in y_values.items():
    spline = make_interp_spline(x_values, values, k=3)
    x_smooth = np.linspace(x_values.min(), x_values.max(), 300)
    y_smooth = spline(x_smooth)

    slopes = np.diff(y_smooth) / np.diff(x_smooth)
    all_max_slopes.append(np.max(np.abs(slopes)))

threshold_for_off = np.percentile(all_max_slopes, 50)

for key, values in y_values.items():
    spline = make_interp_spline(x_values, values, k=3)
    x_smooth = np.linspace(x_values.min(), x_values.max(), 300)
    y_smooth = spline(x_smooth)

    slopes = np.diff(y_smooth) / np.diff(x_smooth)
    max_slope = np.max(np.abs(slopes))

    if max_slope < threshold_for_off:
        curve_labels[key] = "Off"
        plt.plot(x_smooth, y_smooth, label=f'{key} (Off)', linestyle='-.')
    else:
        curve_labels[key] = "On"
        slopes_right_to_left = np.diff(y_smooth[::-1]) / np.diff(x_smooth[::-1])
        on_region_start_index = len(slopes_right_to_left) - np.argmax(slopes_right_to_left > np.percentile(slopes_right_to_left, 75)) - 1

        if on_region_start_index < len(x_smooth):
            x_on_region = x_smooth[on_region_start_index:].reshape(-1, 1)
            y_on_region = y_smooth[on_region_start_index:].reshape(-1, 1)

            reg = LinearRegression().fit(x_on_region, y_on_region)
            gm = reg.coef_[0][0]
            gm_values[key] = gm

            plt.plot(x_smooth, y_smooth, label=f'{key} (On)')
            plt.plot(x_on_region, reg.predict(x_on_region), linestyle='--')

            extension_factor = 0.1
            extended_x = np.linspace(x_smooth[on_region_start_index] - extension_factor, x_smooth[-1] + extension_factor, 100).reshape(-1, 1)
            # extended_x = np.linspace(x_smooth[on_region_start_index], x_smooth[-1], 100).reshape(-1, 1)
            plt.plot(extended_x, reg.predict(extended_x), linestyle=':', linewidth=2, label=f'Slope {key} (gm={gm:.4f}, R^2={reg.score(x_on_region, y_on_region):.2f})')
        else:
            gm_values[key] = np.nan

plt.xlabel('VGS (V)')
plt.ylabel('Isd (A)')
plt.legend(title='Vd values', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.title('Isd vs VGS with gm slopes (On/Off Region)')
plt.grid(True)
plt.show()

for key, gm in gm_values.items():
    label = curve_labels[key]
    if label == "On":
        print(f'gm for Vd = {key} (On): {gm:.4f}')
    else:
        print(f'Curve for Vd = {key} is Off, showing linear or inactive behavior.')